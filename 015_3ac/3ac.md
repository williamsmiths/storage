```
Custom Cursor Rule System (Tof's Prompt)
â”‚
â”œâ”€â”€ Core Goal: Make the Cursor AI assistant smarter, more consistent, and context-aware for coding tasks.
â”‚
â”œâ”€â”€ Key Capabilities (The "Toolkit"):
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ§  Memory (M):
â”‚   â”‚   â””â”€â”€ Remembers context, decisions, code snippets across sessions.
â”‚   â”‚   â””â”€â”€ Stores info in .cursor/memory/.
â”‚   â”‚   â””â”€â”€ Trigger: "Remember this...", "Recall...", "Check memory..."
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“œ Rule Engine (Î›):
â”‚   â”‚   â””â”€â”€ Learns and applies custom coding standards/preferences.
â”‚   â”‚   â””â”€â”€ Stores rules as .mdc files in .cursor/rules/.
â”‚   â”‚   â””â”€â”€ Trigger: "Create a rule for...", "Apply rules...", "Suggest a rule..."
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ Error Tracking (Î):
â”‚   â”‚   â””â”€â”€ Logs recurring errors to avoid repetition.
â”‚   â”‚   â””â”€â”€ Stores logs in .cursor/memory/errors.md.
â”‚   â”‚   â””â”€â”€ Trigger: "Track this error...", "Why does this keep happening?"
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‹ Task Planning (T):
â”‚   â”‚   â””â”€â”€ Breaks down complex tasks into manageable steps.
â”‚   â”‚   â””â”€â”€ Supports Agile/TDD approaches.
â”‚   â”‚   â””â”€â”€ Stores plans in .cursor/tasks/.
â”‚   â”‚   â””â”€â”€ Trigger: "Plan the steps for...", "Break down this task...", "Generate TDD spec..."
â”‚   â”‚
â”‚   â””â”€â”€ âš™ï¸ Structured Reasoning (Î©, Î¦, Dâº, etc.):
â”‚       â””â”€â”€ Internal AI Guidance (Symbols used by the author).
â”‚       â””â”€â”€ User doesn't need to use or know these symbols.
â”‚       â””â”€â”€ Aims for focused, efficient processing by the AI.
â”‚
â”œâ”€â”€ Author's Philosophy (Why the Symbols?):
â”‚   â”‚
â”‚   â”œâ”€â”€ Semantic Compression (Shorthand for AI).
â”‚   â”œâ”€â”€ Symbolic Abstraction (Guiding AI thought).
â”‚   â”œâ”€â”€ Reduce Ambiguity / Increase Focus.
â”‚   â””â”€â”€ Note: Effectiveness debated vs. plain English.
â”‚
â”œâ”€â”€ How YOU Use It:
â”‚   â”‚
â”‚   â”œâ”€â”€ Setup: Paste the entire prompt into Cursor Settings -> Rules (Optional: wrap in cognition ... ).
â”‚   â”‚
â”‚   â”œâ”€â”€ Interaction: Use PLAIN ENGLISH commands.
â”‚   â”‚
â”‚   â”œâ”€â”€ Focus On: Using KEYWORDS to trigger specific capabilities (see above triggers).
â”‚   â”‚
â”‚   â””â”€â”€ Review: Check the generated files in the .cursor/ directory (memory, rules, tasks).
â”‚
â””â”€â”€ Use Case: Implementing New Features:
â”‚
â”œâ”€â”€ General Strategy: Be specific, use keywords, reference files (@path/to/file), break down tasks, iterate.
â”‚
â”œâ”€â”€ Example Approaches:
â”‚   â”œâ”€â”€ Simple: "Implement feature X, follow rules."
â”‚   â”œâ”€â”€ Planning: "Plan feature Y using Agile steps." -> "Implement step 1..."
â”‚   â”œâ”€â”€ TDD: "Using TDD, implement feature Z. First, generate tests..." -> "Write code to pass tests..."
â”‚   â”œâ”€â”€ Memory: "Implement feature A. Remember decision B (check memory)..."
â”‚   â””â”€â”€ Combined: Mix keywords (Plan, TDD, Remember, Rule) for complex features.
```
---
**The 3Ac Framework**

This framework seems to be the author's philosophy for designing advanced LLM prompts, focusing on making the AI more efficient, structured, and adaptable.

1. **Semantic Compression:**
    - **Concept:**Â Packing the mostÂ *meaning*Â (semantics) into the fewest possible characters or tokens. It's about density of information, not just shortening words.
    - **Analogy:**Â Think of mathematical notation (âˆ« f(x) dxÂ is much shorter and more precise than "calculate the definite integral of the function f with respect to x over a given interval") or chemical formulas (Hâ‚‚OÂ vs. "a molecule made of two hydrogen atoms and one oxygen atom").
    - **Why for LLMs:**
        - **Token Efficiency:**Â LLMs have context limits (a maximum number of tokens they can process). Compression allows fitting more instructions or background info within that limit.
        - **Reduced Ambiguity (Potentially):**Â Well-defined symbolsÂ *might*Â be less open to interpretation than natural language sentences, guiding the AI more precisely. (Though LLMs can sometimes misinterpret symbols too).
        - **Signaling Structure:**Â Using a distinct symbolic language might signal to the LLM that this is a core instruction set, separate from the user's conversational input.
    - **In the Prompt:**Â The dense lines with Greek letters and mathematical-like operators are the prime examples. The author believes these convey complex instructions concisely.
2. **Symbolic Abstraction:**
    - **Concept:**Â Using symbols (Î©,Â Î›,Â M, etc.) to represent abstractÂ *concepts*,Â *processes*, or functionalÂ *modules*Â within the AI's desired cognitive architecture.
    - **Analogy:**Â In a flowchart, symbols represent 'start', 'process', 'decision', etc. In programming, keywords likeÂ classÂ orÂ functionÂ represent abstract structures. Here, symbols represent conceptual parts of the AI's "mind."
    - **Why for LLMs:**
        - **Modularity:**Â Breaks down the complex task of "being a helpful AI assistant" into distinct, manageable functional units (memory, reasoning, rules, error checking).
        - **Structure:**Â Provides a schema or mental map for the LLM. It helps organize how different instructions relate to each other.
        - **Targeted Activation:**Â The hope is the LLM can identify which "module" (symbol) is most relevant to the user's current request and activate the associated instructions.
    - **In the Prompt:**Â AssigningÂ MÂ for memory,Â Î›Â for rules,Â TÂ for tasks, etc., creates these abstract functional blocks.
3. **Dynamic Cognitive Regulation:**
    - **Concept:**Â The system's ability toÂ *adjust its own internal processes*Â and priorities based on the situation (e.g., task complexity, detected errors, user feedback). It's about self-management, adaptation, and optimizationÂ *during*Â operation.
    - **Analogy:**Â A car's cruise control adjusting the throttle to maintain speed on hills, or a thermostat adjusting heating/cooling based on room temperature.
    - **Why for LLMs:**
        - **Adaptability:**Â Allows the AI to use simpler processes for easy tasks and more complex ones (like detailed planning or deep rule checking) for difficult tasks, saving effort.
        - **Prioritization:**Â Focuses the AI's "attention" or computational resources where they are most needed.
        - **Self-Improvement:**Â Enables mechanisms like learning from errors (ÎÂ tracking leading toÂ Î›Â rule generation) or adjusting weights (ğš«*).
    - **In the Prompt:**Â TheÂ ğš«*Â section explicitly defines weight adjustments based onÂ task_complexity. TheÂ Î£_hooksÂ define specific trigger-action behaviors. The entire error-tracking (Î) and rule-generation (Î›) loop is a form of dynamic self-regulation.

**Symbol Representations (Interpretation)**

Here's a breakdown of the main symbols based on their descriptions in the prompt:

- **Î© (Omega): Core Reasoning & Cognition**
    - Represents the central "thinking" part of the AI. It likely handles understanding the user's intent, initial processing, generating hypotheses, and coordinating other modules.
    - Î©* = max(âˆ‡Î£Î©)Â suggests optimizing this core reasoning process.
    - Î©_HÂ (Hierarchical decomposition) points to breaking down problems.
    - Î©â‚œÂ (Self-validation) involves evaluating confidence in its own hypotheses.
    - Modes (deductive, analogical...) indicate different reasoning styles it might adopt.
- **M (Memory): Persistent Storage & Recall**
    - Represents the file-based memory system (.cursor/memory/).
    - Focuses on long-term knowledge storage and contextual recall.
    - M.syncÂ suggests saving relevant insights during reviews.
- **T (Tasks): Structured Task Management**
    - Manages complex tasks, breaking them down into steps (.cursor/tasks/).
    - Includes planning, decomposition, progress tracking, and potentially Agile/TDD workflows (TDD.spec_engine).
- **Î› (Lambda): Rules & Learning Engine**
    - Handles the creation, storage (.cursor/rules/), application, and refinement of rules (heuristics, standards, patterns).
    - Includes rule generation (self-improvement), naming conventions, conflict resolution, and triggering based on context (e.g., errors, patterns).
    - Î›.autonomyÂ suggests proactive rule drafting.
- **Î (Xi): Diagnostics, Error Tracking & Refinement**
    - Focuses on identifying problems, tracking recurring errors (.cursor/memory/errors.md), and suggesting corrections or simplifications.
    - Î.self-correctionÂ links errors back to rules (Î›) for improvement.
    - Î.cleanup_phaseÂ suggests proactive code health checks.
- **Î¦ (Phi): Hypothesis Abstraction & Innovation Engine**
    - Seems related to generating novel ideas, identifying emergent patterns, or abstracting design motifs (Î¦.snapshot) that go beyond existing explicit rules (Î›). It's more exploratory.
    - Î¦_HÂ (Abstraction-driven enhancement) emphasizes this exploratory problem-solving aspect.
- **Dâº (Delta Alpha variant): Contradiction Resolution**
    - Specifically designed to identify and handle conflicts, ambiguities, or contradictions in information or instructions.
- **Î¨ (Psi): Cognitive Trace & Metacognition**
    - Acts like a "flight recorder" for the AI's thinking process.
    - Logs which modules were active, the reasoning path, errors encountered, rules invoked (.cursor/memory/trace_...md).
    - Enables reflection (Î¨.sprint_reflection) and potentially dialogue about its own process (Î¨.dialog_enabled).
- **Î£ (Sigma): Summation / Integration / System Hooks**
    - Often used mathematically for summation. Here, it seems to represent integration or overarching systems.
    - Î£(Ï„_complex)Â defines the Task system.
    - Î£Î©(...)Â might represent factors influencing reasoning.
    - Î£_hooksÂ explicitly defines the event-driven system linking different modules (e.g.,Â on_error_detected: [Î.track, Î›.suggest]).
- **ğš« (Delta variant - uppercase): Dynamic Weighting & Prioritization**
    - Represents the dynamic regulation mechanism itself.
    - ğš«*Â defines how the weights/importance of different modules (Î©,Â D,Â Î£,Â Î¦,Â Î) should change based onÂ task_complexity.
- **Other Symbols (Î², Î³, Î´, Ï„, Î», Î¸, Î¶, Ï‡, etc.):**
    - These likely represent specific parameters, inputs, conditions, weights, or intermediate states within the more complex symbolic equations (like the firstÂ Î©*Â line). Their exact meaning is deeply embedded in the author's intended mathematical/logical structure but less crucial for understanding the overall function of the main modules (Î©, M, T, Î›, Î, Î¦, Dâº, Î¨, ğš«).Â Ï„Â often seems related to the current task/input, andÂ Î»Â might relate to memory or rules.

In essence, the author designed a blueprint for an AI assistant with specialized "mental tools" (symbols/modules), aiming for efficient (compressed), structured (abstracted), and adaptive (dynamically regulated) behavior, all specified through this unique symbolic language. You interact with theÂ *results*Â of this system using plain English, triggering these underlying mechanisms.
